#!/usr/bin/env bash
#
# =============================================================================
# Скрипт для массового запуска анализа myAnalysis на существующих reconstructed файлах
# =============================================================================
#
# Назначение:
#   - Находит все файлы rec_*.root в указанной директории
#   - Для каждого файла создаёт отдельный python-скрипт конфигурации Gaudi
#   - Генерирует и подаёт на кластер отдельный job для каждого файла
#   - Выходные файлы анализа сохраняются в отдельной директории результатов
#
# =============================================================================

# ──────────────────────────────────────────────────────────────────────────────
#          Основные настраиваемые параметры (изменяйте здесь)
# ──────────────────────────────────────────────────────────────────────────────

# Корневая директория всего анализа (все поддиректории будут внутри неё)
ANALYSIS_ROOT="/cefs/higgs/kositsin/CEPCSW-tutorial/Analysis/myAnalysis"

# Путь к установленному CEPCSW (там находится run.sh и setup.sh)
CEPCSW_ROOT="/cefs/higgs/kositsin/CEPCSW-tutorial"

# Название процесса (используется в именах файлов и поддиректориях)
PROCESS_NAME="E240_qqHinvi"

# Путь к директории с reconstructed файлами (только для чтения, ничего туда не пишем)
RECO_DIR="/cefs/higgs/liugeliang/CEPC/202501/Production/Hinvi/E240_qqHinvi/Combined"

# Шаблон имени входных файлов (ls-шаблон)
RECO_FILE_PATTERN="rec_${PROCESS_NAME}_*.root"

# Включить/выключить подачу заданий (удобно для отладки)
SUBMIT_JOBS=1

# Группа для hep_sub и требуемая память (в МБ)
HEP_GROUP="higgs"
MEMORY_MB=6000

# ──────────────────────────────────────────────────────────────────────────────
#          Внутренние переменные (лучше не трогать)
# ──────────────────────────────────────────────────────────────────────────────

# Текущая дата-время в формате MMDDHHMM для уникальности логов
TIMESTAMP=$(date +%m%d%H%M)

# Поддиректории внутри ANALYSIS_ROOT (структурируем всё отдельно)
SCRIPT_DIR="${ANALYSIS_ROOT}/scripts"        # Для шаблонов (temp_ana.py) и этого скрипта
JOB_DIR="${ANALYSIS_ROOT}/jobs/${PROCESS_NAME}"  # Для генерированных ana_*.py и sub_*.sh
RES_DIR="${ANALYSIS_ROOT}/results/${PROCESS_NAME}"  # Для результатов (ana_*.root)
LOG_DIR="${ANALYSIS_ROOT}/logs/${PROCESS_NAME}"     # Для логов (*.out и *.err)

# ──────────────────────────────────────────────────────────────────────────────
#          Подготовка окружения
# ──────────────────────────────────────────────────────────────────────────────

# Добавляем hep_sub в PATH (если ещё не добавлен)
export PATH="/cvmfs/common.ihep.ac.cn/software/hepjob/bin:$PATH"

# Создаём все необходимые директории, если их нет
mkdir -p "$SCRIPT_DIR" "$JOB_DIR" "$RES_DIR" "$LOG_DIR" || {
    echo "Ошибка: не удалось создать директории" >&2
    exit 1
}

# ──────────────────────────────────────────────────────────────────────────────
#          Поиск входных файлов
# ──────────────────────────────────────────────────────────────────────────────

echo "Поиск reconstructed файлов..."
echo "Путь: ${RECO_DIR}/${RECO_FILE_PATTERN}"

mapfile -t RECO_FILES < <(ls -v "${RECO_DIR}"/${RECO_FILE_PATTERN} 2>/dev/null)

if [ ${#RECO_FILES[@]} -eq 0 ]; then
    echo "ОШИБКА: Не найдено ни одного файла по шаблону ${RECO_FILE_PATTERN}"
    echo "       Проверьте путь и наличие файлов!"
    exit 1
fi

printf "Найдено файлов: %d\n\n" "${#RECO_FILES[@]}"

# ──────────────────────────────────────────────────────────────────────────────
#          Основной цикл обработки каждого файла
# ──────────────────────────────────────────────────────────────────────────────

job_counter=0

for input_file in "${RECO_FILES[@]}"; do
    # Нумерация с ведущими нулями (00001, 00002, ...)
    idx=$(printf "%05d" "$job_counter")

    # Формируем имя выходного файла анализа
    output_file="${RES_DIR}/ana_${PROCESS_NAME}_${idx}.root"

    # Генерируем конфигурационный python-скрипт для этого файла
    sed -e "s|{rec_path}|${input_file}|g" \
        -e "s|{ana_path}|${output_file}|g" \
        "${SCRIPT_DIR}/temp_ana.py" > "${JOB_DIR}/ana_${idx}.py" || {
        echo "Ошибка при генерации ana_${idx}.py" >&2
        continue
    }

    # ── Создание и подача задания ───────────────────────────────────────────
    if [ "$SUBMIT_JOBS" -eq 1 ]; then
        sub_script="${JOB_DIR}/sub_ana_${PROCESS_NAME}_${idx}.sh"

        cat > "$sub_script" << EOF
#!/usr/bin/env bash
# Автоматически сгенерировано $(date '+%Y-%m-%d %H:%M:%S')

cd "${CEPCSW_ROOT}" || { echo "Не удалось перейти в \${CEPCSW_ROOT}"; exit 1; }
source "${CEPCSW_ROOT}/setup.sh" || { echo "Ошибка source setup.sh"; exit 1; }

echo "Запуск анализа для файла:"
echo "  Input:  ${input_file}"
echo "  Output: ${output_file}"

time ./run.sh "${JOB_DIR}/ana_${idx}.py"

echo "Завершение задания для индекса ${idx}"
EOF

        chmod +x "$sub_script"

        # Подача задания на кластер
        hep_sub "$sub_script" \
            -g "$HEP_GROUP" \
            -mem "$MEMORY_MB" \
            -o "${LOG_DIR}/ana_${TIMESTAMP}_${PROCESS_NAME}_${idx}.out" \
            -e "${LOG_DIR}/ana_${TIMESTAMP}_${PROCESS_NAME}_${idx}.err"

        printf "Задание подано: %5d   %s\n" "$job_counter" "$(basename "$input_file")"
    else
        printf "Сгенерирован скрипт (без подачи): ana_%05d.py\n" "$job_counter"
    fi

    ((job_counter++))
done

# ──────────────────────────────────────────────────────────────────────────────
#          Итоговая информация
# ──────────────────────────────────────────────────────────────────────────────

echo
echo "──────────────────────────────────────────────────────────────"
echo "Всего обработано файлов: ${job_counter}"
if [ "$SUBMIT_JOBS" -eq 1 ]; then
    echo "Все задания успешно поданы на кластер"
    echo "Логи будут в: ${LOG_DIR}/*.out и *.err"
else
    echo "Режим без подачи заданий (только генерация конфигов)"
fi
echo "Готовые файлы анализа появятся здесь:"
echo "  ${RES_DIR}/ana_${PROCESS_NAME}_*.root"
echo "──────────────────────────────────────────────────────────────"
